{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84355450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a41733",
   "metadata": {},
   "source": [
    "# RAG Support for ShellSage\n",
    "\n",
    "This notebook implements Retrieval-Augmented Generation (RAG) support for ShellSage using local man pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa95250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import lancedb\n",
    "from chonkie import RecursiveChunker\n",
    "from model2vec import Model2Vec\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5174f1",
   "metadata": {},
   "source": [
    "## Man Page Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092778bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_man_pages() -> List[Dict[str, str]]:\n",
    "    \"\"\"Get all available man pages on the system.\n",
    "    Returns a list of dicts containing title, section, and path for each man page.\"\"\"\n",
    "    result = subprocess.run(['apropos', '.'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    pages = []\n",
    "    \n",
    "    for line in result.stdout.splitlines():\n",
    "        if not line.strip(): continue\n",
    "        match = re.match(r'([^(]+)\\(([^)]+)\\)\\s*-\\s*(.+)', line)\n",
    "        if not match: continue\n",
    "            \n",
    "        name, section, desc = match.groups()\n",
    "        name = name.strip()\n",
    "        \n",
    "        try:\n",
    "            path = subprocess.check_output(['man', '-w', name], text=True).strip()\n",
    "            pages.append({\n",
    "                'title': name,\n",
    "                'section': section,\n",
    "                'description': desc.strip(),\n",
    "                'path': path\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_man_page(path: str) -> str:\n",
    "    \"\"\"Read a man page and return its text content.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['man', path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        return result.stdout\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793933f",
   "metadata": {},
   "source": [
    "## Text Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579918f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def chunk_text(text: str) -> List[str]:\n",
    "    \"\"\"Chunk text using Chonkie's RecursiveChunker.\"\"\"\n",
    "    chunker = RecursiveChunker()\n",
    "    chunks = chunker(text)\n",
    "    return [chunk.text for chunk in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0598ef",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_embeddings(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings for a list of text chunks using Model2Vec.\"\"\"\n",
    "    model = Model2Vec(\"minishlab/M2V_base_output\")\n",
    "    return [model.embed(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d4dc3",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76280d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test man page extraction\n",
    "pages = get_man_pages()\n",
    "print(f\"Found {len(pages)} man pages\\n\")\n",
    "print(\"Example entries:\")\n",
    "for page in pages[:3]:\n",
    "    print(f\"\\nTitle: {page['title']}\")\n",
    "    print(f\"Section: {page['section']}\")\n",
    "    print(f\"Description: {page['description']}\")\n",
    "    print(f\"Path: {page['path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad9fec",
   "metadata": {},
   "source": [
    "## LanceDB Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def init_db(db_path: str = \"man_index.lance\") -> lancedb.db.LanceDB:\n",
    "    \"\"\"Initialize or open a LanceDB database.\"\"\"\n",
    "    return lancedb.connect(db_path)\n",
    "\n",
    "def create_chunks_table(db: lancedb.db.LanceDB):\n",
    "    \"\"\"Create or replace the man page chunks table.\"\"\"\n",
    "    return db.create_table(\n",
    "        \"man_chunks\",\n",
    "        data=[{\n",
    "            \"title\": \"\",\n",
    "            \"section\": \"\",\n",
    "            \"chunk\": \"\",\n",
    "            \"vector\": get_embeddings([\"\"])[0]  # Get schema from empty embedding\n",
    "        }],\n",
    "        mode=\"create_or_replace\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad24944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def index_man_pages(db_path: str = \"man_index.lance\"):\n",
    "    \"\"\"Index all man pages into the vector database.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = create_chunks_table(db)\n",
    "    \n",
    "    pages = get_man_pages()\n",
    "    for page in pages:\n",
    "        text = read_man_page(page['path'])\n",
    "        if not text: continue\n",
    "            \n",
    "        chunks = chunk_text(text)\n",
    "        vectors = get_embeddings(chunks)\n",
    "        \n",
    "        # Insert chunks and vectors\n",
    "        for chunk, vector in zip(chunks, vectors):\n",
    "            table.add([{\n",
    "                \"title\": page['title'],\n",
    "                \"section\": page['section'],\n",
    "                \"chunk\": chunk,\n",
    "                \"vector\": vector\n",
    "            }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def query_man_pages(query: str, top_k: int = 5, db_path: str = \"man_index.lance\") -> List[Dict]:\n",
    "    \"\"\"Query the man page index for relevant chunks.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = db.open_table(\"man_chunks\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_vector = get_embeddings([query])[0]\n",
    "    \n",
    "    # Search for similar chunks\n",
    "    results = table.search(query_vector).limit(top_k).to_list()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae6b39",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6252aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index some man pages (this may take a while)\n",
    "index_man_pages()\n",
    "\n",
    "# Try a query\n",
    "results = query_man_pages(\"how to list files in a directory\")\n",
    "for r in results:\n",
    "    print(f\"\\nFrom: {r['title']}({r['section']})\")\n",
    "    print(f\"Chunk: {r['chunk'][:200]}...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
