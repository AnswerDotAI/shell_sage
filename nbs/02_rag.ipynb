{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c956579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5dc37",
   "metadata": {},
   "source": [
    "# RAG Support for ShellSage\n",
    "\n",
    "Implementing RAG functionality using local man pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import lancedb\n",
    "from chonkie import RecursiveChunker\n",
    "from model2vec import StaticModel\n",
    "import subprocess\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def init_db(db_path=\"man_index.lance\"):\n",
    "    \"\"\"Initialize or open a LanceDB database.\"\"\"\n",
    "    os.makedirs(os.path.dirname(db_path) if os.path.dirname(db_path) else '.', exist_ok=True)\n",
    "    return lancedb.connect(db_path)\n",
    "\n",
    "def create_chunks_table(db):\n",
    "    \"\"\"Create or replace the man page chunks table.\"\"\"\n",
    "    data = pd.DataFrame({\n",
    "        'title': [''],\n",
    "        'section': [''],\n",
    "        'chunk': [''],\n",
    "        'vector': [[0.0] * 256]\n",
    "    })\n",
    "    return db.create_table(\"man_chunks\", data=data, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32502b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_man_pages():\n",
    "    \"\"\"Get all available man pages on the system.\"\"\"\n",
    "    result = subprocess.run(['apropos', '-l', '.'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    pages = []\n",
    "    \n",
    "    for line in result.stdout.splitlines():\n",
    "        if not line.strip(): continue\n",
    "        try:\n",
    "            name, section = line.split('(', 1)\n",
    "            section = section.split(')', 1)[0]\n",
    "            name = name.strip()\n",
    "            \n",
    "            path = subprocess.check_output(['man', '-w', name], text=True).strip()\n",
    "            if os.path.exists(path):\n",
    "                pages.append({\n",
    "                    'title': name,\n",
    "                    'section': section,\n",
    "                    'path': path\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logging.debug(f\"Skipping line '{line}': {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_man_page(path):\n",
    "    \"\"\"Read a man page and return its text content.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['man', path], capture_output=True, text=True)\n",
    "        return result.stdout if result.returncode == 0 else \"\"\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to read man page {path}: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a661c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def chunk_text(text):\n",
    "    \"\"\"Chunk text using Chonkie's RecursiveChunker.\"\"\"\n",
    "    chunker = RecursiveChunker(\n",
    "        tokenizer=\"gpt2\",\n",
    "        chunk_size=512,\n",
    "        min_characters_per_chunk=12\n",
    "    )\n",
    "    chunks = chunker.chunk(text)\n",
    "    return [chunk.text for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28846eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_embeddings(texts):\n",
    "    \"\"\"Get embeddings using Model2Vec.\"\"\"\n",
    "    model = StaticModel.from_pretrained(\"minishlab/M2V_base_output\")\n",
    "    vectors = model.encode(texts)\n",
    "    return [vector.astype(np.float32).tolist() for vector in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def index_man_pages(db_path=\"man_index.lance\"):\n",
    "    \"\"\"Index all man pages into the vector database.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = create_chunks_table(db)\n",
    "    \n",
    "    pages = get_man_pages()\n",
    "    logging.info(f\"Found {len(pages)} man pages to index\")\n",
    "    \n",
    "    all_data = []\n",
    "    total_chunks = 0\n",
    "    \n",
    "    for page in pages:\n",
    "        try:\n",
    "            logging.info(f\"Processing {page['title']}({page['section']})\")\n",
    "            text = read_man_page(page['path'])\n",
    "            if not text:\n",
    "                logging.warning(f\"Empty content for {page['title']}({page['section']})\")\n",
    "                continue\n",
    "                \n",
    "            chunks = chunk_text(text)\n",
    "            if not chunks:\n",
    "                logging.warning(f\"No chunks created for {page['title']}({page['section']})\")\n",
    "                continue\n",
    "                \n",
    "            vectors = get_embeddings(chunks)\n",
    "            \n",
    "            for chunk, vector in zip(chunks, vectors):\n",
    "                all_data.append({\n",
    "                    \"title\": page['title'],\n",
    "                    \"section\": page['section'],\n",
    "                    \"chunk\": chunk,\n",
    "                    \"vector\": vector\n",
    "                })\n",
    "            \n",
    "            total_chunks += len(chunks)\n",
    "            logging.info(f\"Processed {len(chunks)} chunks for {page['title']} (total: {total_chunks})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {page['title']}({page['section']}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        table.add(df)\n",
    "        logging.info(f\"Added all {len(df)} chunks to database\")\n",
    "    \n",
    "    return total_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def query_man_pages(query: str, top_k: int = 5, db_path: str = \"man_index.lance\"):\n",
    "    \"\"\"Query the indexed man pages and return the most relevant chunks.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = db.open_table(\"man_chunks\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_vector = get_embeddings([query])[0]\n",
    "    \n",
    "    # Search the database\n",
    "    results = table.search(query_vector).limit(top_k).to_pandas()\n",
    "    \n",
    "    return [{\n",
    "        'title': row['title'],\n",
    "        'section': row['section'],\n",
    "        'chunk': row['chunk'],\n",
    "        'score': row['_distance']\n",
    "    } for _, row in results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef328f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the implementation\n",
    "test_db = \"test_man_index.lance\"\n",
    "if os.path.exists(test_db):\n",
    "    import shutil\n",
    "    shutil.rmtree(test_db)\n",
    "\n",
    "print(\"Starting man page indexing...\")\n",
    "total_chunks = index_man_pages(test_db)\n",
    "\n",
    "# Verify database contents\n",
    "db = lancedb.connect(test_db)\n",
    "table = db.open_table(\"man_chunks\")\n",
    "df = table.to_pandas()\n",
    "print(f\"\\nDatabase statistics:\")\n",
    "print(f\"Total chunks indexed: {len(df)}\")\n",
    "print(f\"Expected chunks: {total_chunks}\")\n",
    "\n",
    "# Test querying\n",
    "print(\"\\nTesting query functionality...\")\n",
    "query = \"how to create a jar file\"\n",
    "results = query_man_pages(query, top_k=3, db_path=test_db)\n",
    "\n",
    "print(f\"\\nTop 3 results for query: '{query}'\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {result['title']}({result['section']}) - Score: {result['score']:.4f}\")\n",
    "    print(f\"Chunk: {result['chunk'][:200]}...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
