{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eea628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6ca48",
   "metadata": {},
   "source": [
    "# RAG Support for ShellSage\n",
    "\n",
    "Implementing RAG functionality using local man pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import subprocess\n",
    "import logging\n",
    "import os\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "from chonkie import RecursiveChunker\n",
    "from model2vec import StaticModel\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_man_pages():\n",
    "    \"\"\"Get all available man pages on the system.\"\"\"\n",
    "    result = subprocess.run(['apropos', '-l', '.'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    pages = []\n",
    "    \n",
    "    for line in result.stdout.splitlines():\n",
    "        if not line.strip(): continue\n",
    "        try:\n",
    "            name, section = line.split('(', 1)\n",
    "            section = section.split(')', 1)[0]\n",
    "            name = name.strip()\n",
    "            \n",
    "            path = subprocess.check_output(['man', '-w', name], text=True).strip()\n",
    "            if os.path.exists(path):\n",
    "                pages.append({\n",
    "                    'title': name,\n",
    "                    'section': section,\n",
    "                    'path': path\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logging.debug(\"Skipping line \" + str(line) + \": \" + str(e))\n",
    "            continue\n",
    "            \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc344d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_man_page(path):\n",
    "    \"\"\"Read a man page and return its text content.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['man', path], capture_output=True, text=True)\n",
    "        return result.stdout if result.returncode == 0 else \"\"\n",
    "    except Exception as e:\n",
    "        logging.warning(\"Failed to read man page \" + str(path) + \": \" + str(e))\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ef899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def chunk_text(text):\n",
    "    \"\"\"Chunk text using Chonkie's RecursiveChunker.\"\"\"\n",
    "    chunker = RecursiveChunker(\n",
    "        tokenizer=\"gpt2\",\n",
    "        chunk_size=512,\n",
    "        min_characters_per_chunk=12\n",
    "    )\n",
    "    chunks = chunker.chunk(text)\n",
    "    return [chunk.text for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_embeddings(texts):\n",
    "    \"\"\"Get embeddings using Model2Vec.\"\"\"\n",
    "    model = StaticModel.from_pretrained(\"minishlab/M2V_base_output\")\n",
    "    vectors = model.encode(texts)\n",
    "    return [vector.tolist() for vector in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def init_db(db_path=\"man_index.lance\"):\n",
    "    \"\"\"Initialize or open a LanceDB database.\"\"\"\n",
    "    return lancedb.connect(db_path)\n",
    "\n",
    "def create_chunks_table(db):\n",
    "    \"\"\"Create or replace the man page chunks table.\"\"\"\n",
    "    schema = pa.schema([\n",
    "        pa.field(\"title\", pa.string()),\n",
    "        pa.field(\"section\", pa.string()),\n",
    "        pa.field(\"chunk\", pa.string()),\n",
    "        pa.field(\"vector\", pa.list_(pa.float32(), 256))\n",
    "    ])\n",
    "    return db.create_table(\"man_chunks\", schema=schema, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f072cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def index_cmd(db_path=\"man_index.lance\"):\n",
    "    \"\"\"Index all man pages into the vector database.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = create_chunks_table(db)\n",
    "    \n",
    "    pages = get_man_pages()\n",
    "    logging.info(f\"Found {len(pages)} man pages to index\")\n",
    "    \n",
    "    for page in pages:\n",
    "        try:\n",
    "            logging.info(f\"Processing {page['title']}({page['section']})\")\n",
    "            text = read_man_page(page['path'])\n",
    "            if not text:\n",
    "                continue\n",
    "                \n",
    "            chunks = chunk_text(text)\n",
    "            if not chunks:\n",
    "                continue\n",
    "                \n",
    "            vectors = get_embeddings(chunks)\n",
    "            \n",
    "            data = [{\n",
    "                \"title\": page['title'],\n",
    "                \"section\": page['section'],\n",
    "                \"chunk\": chunk,\n",
    "                \"vector\": vector\n",
    "            } for chunk, vector in zip(chunks, vectors)]\n",
    "            \n",
    "            if data:\n",
    "                table.add(data)\n",
    "                logging.info(f\"Added {len(data)} chunks for {page['title']}({page['section']})\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {page['title']}({page['section']}): {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127017e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def query_man_pages(query, top_k=5, db_path=\"man_index.lance\"):\n",
    "    \"\"\"Search indexed man pages for relevant information.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = db.open_table(\"man_chunks\")\n",
    "    \n",
    "    model = StaticModel.from_pretrained(\"minishlab/M2V_base_output\")\n",
    "    query_vector = model.encode([query])[0].tolist()\n",
    "    \n",
    "    results = table.search(query_vector).limit(top_k).to_list()\n",
    "    return [(r[\"title\"], r[\"section\"], r[\"chunk\"], r[\"_distance\"]) for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d60730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def search_cmd(query, top_k=5, db_path=\"man_index.lance\"):\n",
    "    \"\"\"Search indexed man pages for relevant information.\"\"\"\n",
    "    db = init_db(db_path)\n",
    "    table = db.open_table(\"man_chunks\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    model = StaticModel.from_pretrained(\"minishlab/M2V_base_output\")\n",
    "    query_vector = model.encode([query])[0].tolist()\n",
    "    \n",
    "    # Search and return results\n",
    "    results = table.search(query_vector).limit(top_k).to_list()\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\n=== {result['title']}({result['section']}) ===\")\n",
    "        print(result['chunk'])\n",
    "        print(f\"Similarity score: {result['_distance']}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the implementation\n",
    "pages = get_man_pages()[:3]  # Test with first 3 pages\n",
    "print(f\"Testing with {len(pages)} man pages\")\n",
    "\n",
    "# Initialize database\n",
    "db = init_db()\n",
    "table = create_chunks_table(db)\n",
    "\n",
    "# Process pages\n",
    "for page in pages:\n",
    "    print(f\"\n",
    "Processing {page['title']}({page['section']})\")\n",
    "    text = read_man_page(page['path'])\n",
    "    if text:\n",
    "        chunks = chunk_text(text)\n",
    "        if chunks:\n",
    "            vectors = get_embeddings(chunks)\n",
    "            data = [{\n",
    "                \"title\": page['title'],\n",
    "                \"section\": page['section'],\n",
    "                \"chunk\": chunk,\n",
    "                \"vector\": vector\n",
    "            } for chunk, vector in zip(chunks, vectors)]\n",
    "            table.add(data)\n",
    "            print(f\"Added {len(data)} chunks\")\n",
    "\n",
    "# Test querying\n",
    "print(\"\n",
    "Testing search...\")\n",
    "query = \"how to list files\"\n",
    "results = query_man_pages(query)\n",
    "for title, section, chunk, score in results[:2]:\n",
    "    print(f\"\n",
    "=== {title}({section}) ===\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print(chunk[:200] + \"...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
