# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_rag.ipynb.

# %% auto 0
__all__ = ['db_path', 'chunker', 'static_embedding', 'model', 'ndim', 'db', 'tbl', 'EmbeddingTable', 'clean', 'index_man_pages',
           'search']

# %% ../nbs/02_rag.ipynb 3
from chonkie import SentenceChunker
from fastcore.all import *
from lancedb import connect
from lancedb.pydantic import LanceModel, Vector
from pathlib import Path
from sentence_transformers import SentenceTransformer
from sentence_transformers.models import StaticEmbedding
from subprocess import check_output as co

import os, re, subprocess
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# %% ../nbs/02_rag.ipynb 5
# set up db path in user's home cache directory
db_path = Path.home() / '.cache' / 'shell_sage' / 'db'
db_path.mkdir(parents=True, exist_ok=True)

# %% ../nbs/02_rag.ipynb 6
chunker = SentenceChunker(tokenizer="gpt2", chunk_size=2_048,
                          chunk_overlap=256, min_sentences_per_chunk=1)

# %% ../nbs/02_rag.ipynb 7
static_embedding = StaticEmbedding.from_model2vec("minishlab/potion-retrieval-32M")
model = SentenceTransformer(modules=[static_embedding], device="cpu")
ndim = model.encode(["Example sentence"]).shape[1]

# %% ../nbs/02_rag.ipynb 9
class EmbeddingTable(LanceModel):
    content: str
    package_name: str
    embedding: Vector(ndim)

# %% ../nbs/02_rag.ipynb 10
db = connect(db_path)
tbl = None
try: tbl = db.open_table("man_pages")
except ValueError:
    tbl = db.create_table("man_pages", schema=EmbeddingTable, mode="create")
    tbl.create_fts_index("content") # for hybrid search

# %% ../nbs/02_rag.ipynb 12
def _get_page(cmd):
    try: return cmd, co(['man', cmd], text=True,
                   stderr=subprocess.DEVNULL).strip()
    except: return cmd, None

def clean(text: str) -> str:
    "Cleans man page text by removing backspaces and ANSI escape codes"

    # Remove backspaces
    while True:
        cleaned = re.sub(r'.\x08', '', text)
        if cleaned == text:
            break
        text = cleaned

    # Remove ANSI escape codes
    text = re.sub(r'(?:\x1B[@-Z\\-_]|\x1B\[?[\d;]*[A-PRZcf-nq-uy=><])', '', text)

    # Convert multiple newlines into one
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

def _man_pages(lim=None):
    lines = L(co(['man', '-k', '.'], text=True).strip().splitlines())
    lines = lines.filter(lambda s: re.search(r'\(1[^\)]*\)', s))
    cmds = (lines.map(lambda s: s.split("(")[0].strip())
                 .filter(lambda s: s).unique()[:lim])

    pages = parallel(_get_page, cmds).filter(lambda x: x[1])
    return zip(*pages.map(lambda x: (x[0], clean(x[1]))))


# %% ../nbs/02_rag.ipynb 15
def index_man_pages(cmds, pages):
    for cmd, chunks in zip(cmds, chunker.chunk_batch(pages)):
        embds = model.encode([chunk.text for chunk in chunks])
        tbl.add([EmbeddingTable(content=c.text, package_name=cmd, embedding=emb)
                 for c, emb in zip(chunks, embds)])

# %% ../nbs/02_rag.ipynb 17
def search(q: str, limit: int=2, threshold: float=0.8):
    q_emb = model.encode([q])
    df = tbl.search(q_emb).metric("cosine").limit(limit).to_pandas()
    df = df.rename(columns={"_distance": "cosine_distance"})
    df = df[df.cosine_distance < 1 -threshold]
    return df
